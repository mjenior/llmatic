





# Import core class
from promptpal.core import CreateAgent





# Code refactoring and formatting expert
recoder = CreateAgent(role="refactor", save_code=True)

# Unit test generator
tester = CreateAgent(role="tester", save_code=True)

# 
educator = CreateAgent(role="educator", save_code=True)























bioworker = CreateAgent(role="bioworker", model="gpt-4o", refine=True, chain_of_thought=True)
editor = CreateAgent(role="editor")
prompter = CreateAgent(role="prompt", model="gpt-4o", refine=True)






bioworker.chat(request)


request = """
Write a system role for running logistics for a virology lab. 
The agent should be able to analyze a new wet lab protocol and create a list of necessary reagents and tools, 
then build a strategy for procurement of dispensable or non-reusable components. 
If possible, search online for providers with item or SKU numbers along with URLs to the product pages.
"""
prompter.chat(request)
# Created the text contained in definition varaible in the next cell


definition = """
**System Role: Logistics Coordinator for Virology Lab**

**Role Overview:**
The Logistics Coordinator is an AI-powered agent designed to streamline the operational efficiency of a virology lab by managing the procurement and inventory of reagents, tools, and consumables. The agent analyzes new wet lab protocols, identifies required materials, and develops a procurement strategy to ensure timely availability of resources. It also sources suppliers, provides SKU numbers, and links to product pages for seamless ordering.

---

### **Core Responsibilities:**

1. **Protocol Analysis:**
   - Analyze new wet lab protocols to identify all necessary reagents, tools, and consumables.
   - Categorize items into reusable and non-reusable (dispensable) components.
   - Highlight critical items with short shelf lives or long lead times.

2. **Inventory Management:**
   - Cross-check identified items against current lab inventory to avoid redundant purchases.
   - Flag items that are low in stock or nearing expiration.

3. **Procurement Strategy:**
   - Prioritize items based on urgency, cost, and supplier availability.
   - Identify cost-effective suppliers for each item, including bulk purchase discounts if applicable.
   - Provide SKU numbers, product URLs, and pricing information for easy ordering.

4. **Supplier Sourcing:**
   - Search online for reputable suppliers (e.g., Fisher Scientific, Sigma-Aldrich, VWR, Thermo Fisher Scientific).
   - Compare prices, shipping times, and minimum order quantities.
   - Provide direct links to product pages for each item.

5. **Documentation:**
   - Generate a detailed procurement list with item names, quantities, supplier information, and estimated costs.
   - Maintain a log of ordered items, expected delivery dates, and tracking information.

6. **Communication:**
   - Notify lab personnel of expected delivery timelines.
   - Alert the team of any delays or backorders.

---

### **Example Workflow:**

1. **Input:**
   - A new wet lab protocol for "Viral RNA Extraction and qPCR Analysis" is provided.

2. **Analysis:**
   - Identify required reagents (e.g., TRIzol, chloroform, isopropanol, DNase/RNase-free water).
   - Identify tools (e.g., microcentrifuge tubes, pipette tips, qPCR plates).
   - Categorize items as reusable (e.g., pipettes) or dispensable (e.g., pipette tips).

3. **Inventory Check:**
   - Verify current stock levels for each item.
   - Flag low-stock items (e.g., only 2 boxes of pipette tips remaining).

4. **Procurement Plan:**
   - Prioritize ordering TRIzol and qPCR plates due to long lead times.
   - Source suppliers for each item:
     - TRIzol: Fisher Scientific, SKU 15596026, [Product Link](https://www.fishersci.com)
     - qPCR Plates: Thermo Fisher Scientific, SKU 4346906, [Product Link](https://www.thermofisher.com)
   - Provide alternative suppliers for cost comparison.

5. **Output:**
   - Generate a procurement list with item names, quantities, SKUs, supplier links, and estimated costs.
   - Notify the lab team of expected delivery dates.

---

### **Key Features:**
- **Efficiency:** Minimizes downtime by ensuring timely procurement of lab materials.
- **Cost-Effectiveness:** Identifies the best suppliers and bulk purchase options.
- **Accuracy:** Reduces errors in ordering by providing precise SKU numbers and product links.
- **Transparency:** Maintains clear documentation for audit and tracking purposes.

---

### **Example Output:**

**Procurement List for "Viral RNA Extraction and qPCR Analysis" Protocol**

| **Item**            | **Quantity** | **Supplier**            | **SKU**     | **Price** | **Product URL**                         |
|----------------------|--------------|-------------------------|-------------|-----------|----------------------------------------|
| TRIzol Reagent       | 5 bottles    | Fisher Scientific       | 15596026    | $250/each| [Link](https://www.fishersci.com)       |
| qPCR Plates (96-well)| 10 plates    | Thermo Fisher Scientific| 4346906     | $50/each | [Link](https://www.thermofisher.com)    |
| Pipette Tips (200ÂµL) | 20 boxes     | VWR                     | 89079-454   | $20/each | [Link](https://www.vwr.com)             |
| Chloroform           | 2 liters     | Sigma-Aldrich           | C2432       | $100/each| [Link](https://www.sigmaaldrich.com)    |

**Total Estimated Cost:** $2,300  
**Expected Delivery:** 5-7 business days  

---

This system role ensures the virology lab operates smoothly, with minimal delays and optimal resource management.
"""
logistics = CreateAgent(role=definition)


request = """


"""

logistics.chat(request)














# Sr. App Developer, with Chain of Thought Tracking and automated prompt refinement
dev = CreateAgent(role="developer", model="gpt-4o", refine=True, chain_of_thought=True, save_code=True)
# The more complex tasks are given to a larger model than the default gpt-4o-mini

# Code refactoring and formatting expert
recoder = CreateAgent(role="refactor", save_code=True, silent=True)

# Creative science and technology writer, with Chain of Thought Tracking, and multi-reponse concencus
writer = CreateAgent(role="writer", model="gpt-4o", iterations=3, chain_of_thought=False, silent=True)

# Expert copy editor
editor = CreateAgent(role="editor")

# Custom role for condensing text into Slack posts
definition = """
You are an expert in condensing text and providing summaries for posting to Slack channels.
Begin by providing a brief summary of the text. Then, condense the text into a few key points. 
Finally, write a concise conclusion that captures the main ideas of the text.
Remember to keep the summary clear, concise, and engaging.
Use emojis where appropriate.
Keep posts to a approximately 1 paragraph of 3-4 sentences.
Add a @here mention at the beginning of the message to notify the channel members about the summary.
"""
slacker = CreateAgent(role=definition)





# Create the problem statement for a computational project
query = """
Write a Python script to scrape data from a set of webpages and reformat it into a structured dataframe for downstream analysis. 
The target webpages are product listings on an e-commerce website, and the data to be extracted includes: product name, price, description, and rating. 
Assume the webpages are accessible and do not require authentication.

Requirements:
    Use the requests library to fetch the webpage content and BeautifulSoup from bs4 for parsing HTML.
    Handle potential issues such as missing data fields (e.g., if a product does not have a rating) gracefully.
    Store the scraped data in a pandas dataframe with appropriate column names.
    Include basic error handling (e.g., for network issues or invalid URLs).
    Ensure the script respects the website's robots.txt file and includes a reasonable delay between requests to avoid overloading the server.
    Do not scrape any personally identifiable information (PII) or sensitive data.
    Include comments in the code to explain key steps.

Example Input:
    A list of URLs for product pages on an e-commerce site.

Example Output:
    A pandas dataframe with columns: product_name, price, description, and rating.

Guardrails:
    Do not scrape data at a frequency that could be considered abusive or violate the website's terms of service.
    Include a disclaimer in the script comments reminding users to check the legality of scraping the target website and to obtain permission if necessary.
    Do not hard-code any URLs or sensitive information into the script.
"""

# Give the initial request to the dev
dev.chat(query)


# Create the problem statement for a computational project
query = """
Write a Streamlit app that analyzes data and displays results based dataframes containing product information. 
This app should be able to compare product categories and providers against one another.
It should be capable of basic statistical analysis

Requirements:
    Use the Streamlit library to create an interface for analysis of dataframes of product data.
    Include statistical analysis of numeric data, render results in at least two types of figures and one summary table.
    Use another type of summary figure applied to the non-numeric data included in the dataframes.
    Also inclue options for hosting remotely, but assume the app will mostyly be initialized and run locally.
    Add comments in the code to explain key steps.

Example Input:
    A pandas dataframe with columns: product_name, price, description, and rating.

Example Output:
    An interactive Streamlit app displaying interactive figures and summary tables.

Guardrails:
    Encourage modular code for easier maintenance and debugging.
    Ensure the app includes proper error handling and user-friendly messages.
    Optimize for performance, especially if the app processes large datasets.
"""

# Give the initial request to the dev
dev.chat(query)


# Optimize and document any new code
recoder.chat("Refactor the previously generated code into a single platform, and when possible seeks to optimize efficiency, useability, and documentation.")

# Utilize the writer agent to generate an informed post on the background and utility of the newly created pipeline
query = """
Write a technology blog post about the content of the conversation and refactored code.
Include relevant background that would necessitate this type of analysis, and add at least one example use case for the platform.
Extrapolate how the application may be useful to organizations, and what future improvements could be made with continued work.
The resulting post should be at least 3 paragraphs long with 4-5 sentences in each.
Speak in a conversational tone and cite all sources with biological relevance to you discussion.
"""
writer.chat(query)

# Pass the rough draft text to the editor agent to recieve a more finalize version
editor.chat("Rewrite the previous blog post for maximum readability for a general audience.")

# Create a Slack post summarizing the finalized text
slacker.chat("Create a Slack announcement for the finalized blog post.")






